{"detail":"Error: \n\n--------------------------------------\nC++ Traceback (most recent call last):\n--------------------------------------\n0   paddle::AnalysisPredictor::ZeroCopyRun(bool)\n1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)\n2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)\n3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)\n4   paddle::framework::PirInterpreter::TraceRunImpl()\n5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)\n6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)\n7   paddle::framework::PhiKernelInstruction::Run()\n8   phi::KernelImpl<void (*)(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*), &(void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*))>::Compute(phi::KernelContext*)\n9   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)\n10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const\n11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)\n12  paddle::memory::allocation::Allocator::Allocate(unsigned long)\n13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)\n14  paddle::memory::allocation::Allocator::Allocate(unsigned long)\n15  paddle::memory::allocation::Allocator::Allocate(unsigned long)\n16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)\n17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\n\n----------------------\nError Message Summary:\n----------------------\nResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 524.562500MB memory on GPU 0, 15.221252GB memory has been allocated and available memory is only 515.187500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)\n"}